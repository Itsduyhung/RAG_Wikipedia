# Ollama local (không cần API key)
OLLAMA_BASE_URL=http://host.docker.internal:11434
EMBEDDING_MODEL_NAME=nomic-embed-text
# LLM: qwen2.5:1.5b (nhanh) | phi3:mini / mistral:latest (chậm hơn, chất lượng cao)
LLM_MODEL_NAME=qwen2.5:1.5b
# Context size cho chat: 2048 (qwen2.5:1.5b) | 8192 (mistral)
OLLAMA_NUM_CTX=2048
DIMENSION_OF_MODEL=768

# Provider selection (Render nên dùng gemini/openai vì không có Ollama)
LLM_PROVIDER=ollama
EMBEDDING_PROVIDER=ollama
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash
GEMINI_EMBEDDING_MODEL=models/text-embedding-004
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Database (local Docker)
POSTGRES_USER=rag_user
POSTGRES_PASSWORD=rag_password
POSTGRES_DB=rag_db
DATABASE_URL=postgresql://rag_user:rag_password@postgres:5432/rag_db
# Render: set DATABASE_URL in dashboard = Internal/External URL + ?sslmode=require (không commit .env)

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_URL=redis://redis:6379/0
